# Tableau Comparatif des Algorithmes â€“ PrÃ©diction des Classements Premier League

## Vue d'ensemble du projet

**Objectif gÃ©nÃ©ral** : PrÃ©dire le classement final des Ã©quipes de Premier League (positions 1 Ã  20) Ã  partir de statistiques de performance en fin de saison.

**DonnÃ©es** : 25 saisons (2000-01 Ã  2024-25), ~500 Ã©quipes-saisons, 25 indicateurs de performance.

**MÃ©thodologie** : Division temporelle stricte â€“ entraÃ®nement sur saisons historiques (2000-2024), test sur saison rÃ©cente (2024-25).

---

## RÃ©sumÃ© des Performances

| Algorithme | Objectif MÃ©tier | MAE | RÂ² | PrÃ©cision Â±1 | PrÃ©cision Â±2 | Statut |
|------------|-----------------|-----|-----|--------------|--------------|--------|
| **Random Forest** | PrÃ©dire classement final avec haute prÃ©cision | **0.20** | **0.95** | **100%** | **100%** | âœ… Excellent |
| **XGBoost** | Performance maximale avec rÃ©gularisation | **1.12** | **0.95** | 45% | **90%** | âœ… Excellent |
| **SVM** | DÃ©tecter les risques de relÃ©gation | 1.23 | Ã‰levÃ© | N/A | N/A | âœ… Parfait (100% dÃ©tection relÃ©gation) |
| **KNN** | PrÃ©dire via similaritÃ© entre Ã©quipes | 1.27 | 0.92 | 58% | 80% | âœ… Bon |
| **Decision Tree** | RÃ¨gles interprÃ©tables pour dÃ©cisions | 1.5-2.5 | 0.85-0.92 | 55-65% | 75-85% | âœ… Bon |
| **Gradient Boosting** | Correction sÃ©quentielle des erreurs | 1.62 | Bon | 58% | 72% | âœ… Satisfaisant |

**LÃ©gende** :
- **MAE** : Erreur Absolue Moyenne (en positions) â€“ plus faible = meilleur
- **RÂ²** : Coefficient de dÃ©termination â€“ plus proche de 1 = meilleur
- **PrÃ©cision Â±1** : Pourcentage de prÃ©dictions Ã  Â±1 position de la rÃ©alitÃ©
- **PrÃ©cision Â±2** : Pourcentage de prÃ©dictions Ã  Â±2 positions de la rÃ©alitÃ©

---

## Analyse DÃ©taillÃ©e par Algorithme

### 1ï¸âƒ£ Random Forest â€” Champion de la PrÃ©cision ğŸ†

**Performance** :
- MAE : **0.20 positions** (meilleur rÃ©sultat)
- RÂ² : **0.95** (excellente explication de variance)
- **100%** des prÃ©dictions Ã  Â±1 position
- **80%** de prÃ©dictions parfaites (16/20 Ã©quipes)
- Champion 2024-25 correctement prÃ©dit : Liverpool âœ…

**Forces** :
- âœ… PrÃ©cision exceptionnelle grÃ¢ce Ã  l'ensemble d'arbres
- âœ… Robuste au surapprentissage via bootstrap
- âœ… GÃ¨re bien les interactions non-linÃ©aires
- âœ… EntraÃ®nement rapide (~5 min pour 1 296 combinaisons)

**Faiblesses** :
- âš ï¸ Moins interprÃ©table qu'un arbre unique
- âš ï¸ NÃ©cessite optimisation des hyperparamÃ¨tres

**Cas d'usage idÃ©al** : Production â€“ prÃ©dictions fiables pour analyses stratÃ©giques et paris sportifs

---

### 2ï¸âƒ£ XGBoost â€” RÃ©gularisation Puissante âš¡

**Performance** :
- MAE : **1.12 positions** (test), **0.22** (train)
- RÂ² : **0.95** (test), **0.998** (train)
- **90%** Ã  Â±2 positions, **45%** Ã  Â±1 position
- MAE 2024-25 : **0.40** (12/20 prÃ©dictions parfaites)

**Forces** :
- âœ… Gradient boosting avec forte rÃ©gularisation (L1, L2, structurelle)
- âœ… Excellent compromis biais-variance
- âœ… GÃ¨re naturellement les valeurs manquantes
- âœ… Importance des variables trÃ¨s dÃ©taillÃ©e (Gain + Weight)

**Faiblesses** :
- âš ï¸ Sensible aux hyperparamÃ¨tres
- âš ï¸ NÃ©cessite calibration minutieuse

**Cas d'usage idÃ©al** : CompÃ©titions de machine learning, optimisation de performance maximale

---

### 3ï¸âƒ£ SVM â€” SpÃ©cialiste RelÃ©gation ğŸ”´

**Performance** :
- MAE globale : 1.23 positions
- Classification binaire (relÃ©gation) : **100%** prÃ©cision, rappel, F1-score
- ROC AUC : **1.000** (discrimination parfaite)
- Zone de relÃ©gation : MAE ~3.26 positions

**Forces** :
- âœ… **100% de dÃ©tection des Ã©quipes relÃ©guÃ©es** (positions 18-20)
- âœ… Noyau RBF capture relations complexes
- âœ… ProbabilitÃ©s calibrÃ©es pour Ã©valuation des risques
- âœ… Seuil optimal trouvÃ© via maximisation F1

**Faiblesses** :
- âš ï¸ Moins prÃ©cis pour positions mÃ©dianes (milieu de tableau)
- âš ï¸ CoÃ»teux en calcul pour grands ensembles

**Cas d'usage idÃ©al** : SystÃ¨mes d'alerte prÃ©coce pour clubs en difficultÃ©, Ã©valuation des risques financiers

---

### 4ï¸âƒ£ KNN â€” Apprentissage par ProximitÃ© ğŸ¯

**Performance** :
- MAE : **1.27 positions**
- RÂ² : **0.919**
- **80%** Ã  Â±2 positions
- **58%** Ã  Â±1 position

**Forces** :
- âœ… SimplicitÃ© conceptuelle (basÃ© sur similaritÃ©)
- âœ… Pas d'hypothÃ¨ses sur distribution des donnÃ©es
- âœ… Adaptable (k=7 optimal trouvÃ© par validation croisÃ©e)
- âœ… Utile pour prÃ©dictions en cours de saison

**Faiblesses** :
- âš ï¸ Sensible Ã  l'Ã©chelle des variables (nÃ©cessite normalisation)
- âš ï¸ Lent en prÃ©diction sur grands ensembles
- âš ï¸ Performance dÃ©gradÃ©e en haute dimension

**Cas d'usage idÃ©al** : Comparaisons rapides entre Ã©quipes, benchmarking de performances

---

### 5ï¸âƒ£ Decision Tree â€” Transparence DÃ©cisionnelle ğŸŒ³

**Performance** :
- MAE : **1.5 Ã  2.5** positions (selon profondeur)
- RÂ² : **0.85 Ã  0.92**
- **55-65%** Ã  Â±1 position
- **75-85%** Ã  Â±2 positions

**Forces** :
- âœ… **TrÃ¨s interprÃ©table** â€“ rÃ¨gles if/then claires
- âœ… Visualisation des chemins de dÃ©cision
- âœ… GÃ¨re naturellement interactions et non-linÃ©aritÃ©s
- âœ… Pas de normalisation nÃ©cessaire

**Faiblesses** :
- âš ï¸ Tendance au surapprentissage sans Ã©lagage
- âš ï¸ Instable (petites variations â†’ arbres diffÃ©rents)
- âš ï¸ Moins prÃ©cis que mÃ©thodes ensemblistes

**Cas d'usage idÃ©al** : Rapports pour direction sportive, aide Ã  la dÃ©cision explicable

---

### 6ï¸âƒ£ Gradient Boosting (LightGBM) â€” Correction SÃ©quentielle ğŸ”§

**Performance** :
- MAE : **1.62 positions**
- RMSE : **2.01**
- **72%** Ã  Â±2 positions
- **58%** Ã  Â±1 position
- **38%** de positions exactes

**Forces** :
- âœ… Correction sÃ©quentielle des erreurs rÃ©siduelles
- âœ… EntraÃ®nement rapide avec LightGBM
- âœ… Early stopping automatique (meilleure itÃ©ration trouvÃ©e)
- âœ… Bon compromis prÃ©cision/vitesse

**Faiblesses** :
- âš ï¸ NÃ©cessite tuning minutieux (learning rate, num_leaves)
- âš ï¸ Risque de surapprentissage si mal calibrÃ©

**Cas d'usage idÃ©al** : Pipelines automatisÃ©s, prÃ©dictions en temps rÃ©el

---

## Variables les Plus Importantes (Toutes MÃ©thodes Confondues)

**Top 5 Facteurs PrÃ©dictifs** :

1. **DiffÃ©rence de buts (Goal Difference)** â€“ Indicateur #1 de performance
2. **Points totaux / Points par match** â€“ RÃ©sultat direct des victoires
3. **Taux de victoires (Win Rate)** â€“ Constance dans les rÃ©sultats
4. **Buts marquÃ©s / Buts encaissÃ©s** â€“ EfficacitÃ© offensive et dÃ©fensive
5. **Clean sheets (matches sans but encaissÃ©)** â€“ SoliditÃ© dÃ©fensive

**Facteurs Secondaires** :
- PrÃ©cision des tirs (Shot Accuracy)
- Performance domicile vs extÃ©rieur (Home/Away Win Rate)
- Encodages d'Ã©quipe et saison (force historique, tendances temporelles)

---

## Recommandations par Cas d'Usage

| Besoin | Algorithme RecommandÃ© | Raison |
|--------|----------------------|---------|
| **PrÃ©diction finale de saison** | Random Forest | PrÃ©cision maximale (MAE 0.20) |
| **DÃ©tection risque de relÃ©gation** | SVM | 100% de dÃ©tection, ROC AUC parfait |
| **Analyse explicable pour direction** | Decision Tree | RÃ¨gles claires et visualisables |
| **Pipeline production haute performance** | XGBoost | RÃ©gularisation robuste, excellent RÂ² |
| **Comparaison rapide entre Ã©quipes** | KNN | SimilaritÃ© intuitive, pas de rÃ©entraÃ®nement |
| **SystÃ¨me temps rÃ©el avec mise Ã  jour** | Gradient Boosting | Rapide, adaptatif |

---

## Conclusions ClÃ©s

### âœ… Tous les algorithmes satisfont leurs objectifs mÃ©tier

- **Random Forest** : Meilleure prÃ©cision globale â†’ idÃ©al pour prÃ©dictions finales
- **XGBoost** : Meilleur compromis performance/rÃ©gularisation
- **SVM** : Champion de la dÃ©tection de relÃ©gation (100% prÃ©cision)
- **KNN, Decision Tree, Gradient Boosting** : ComplÃ©mentaires selon le contexte

### ğŸ“Š Enseignements GÃ©nÃ©raux

1. **Les mÃ©thodes ensemblistes dominent** (Random Forest, XGBoost) avec MAE < 1.5
2. **La diffÃ©rence de buts est le prÃ©dicteur #1** dans tous les modÃ¨les
3. **25 saisons de donnÃ©es suffisent** pour des prÃ©dictions fiables
4. **La rÃ©gularisation est cruciale** (XGBoost) pour Ã©viter le surapprentissage
5. **L'interprÃ©tabilitÃ© a un coÃ»t** : Decision Tree moins prÃ©cis mais plus explicable

### ğŸ¯ StratÃ©gie Optimale

**Approche hybride recommandÃ©e** :
1. **Random Forest** pour prÃ©diction finale (MAE 0.20)
2. **SVM** pour alertes relÃ©gation (100% dÃ©tection)
3. **Decision Tree** pour rapports direction (interprÃ©tabilitÃ©)

---

**Date de crÃ©ation** : Novembre 2025  
**Projet** : PrÃ©diction Classements Premier League 
**Repository** : [pl-standings-prediction-project](https://github.com/AtfastrSlushyMaker/pl-standings-prediction-project)
