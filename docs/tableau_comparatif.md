# Tableau Comparatif des Algorithmes ‚Äì Pr√©diction des Classements Premier League

## Vue d'ensemble du projet

**Objectifs M√©tier (Business Objectives)** : 
1.  **BO1 - Classement Final** : Pr√©dire la position finale (1-20) - R√©gression.
2.  **BO2 - Vainqueur de Match** : Pr√©dire qui gagne chaque match (H/D/A) - Classification.
3.  **BO3 - Qualification Top 4** : Identifier les √©quipes Champions League - Classification binaire.

**Datasets** : 
- `team_season_aggregated.csv` (~500 √©quipes-saisons) ‚Üí BO1, BO3.
- `processed_premier_league_combined.csv` (~9500 matchs) ‚Üí BO2.

**M√©thodologie** : Comparaison multi-algorithmes pour chaque objectif m√©tier distinct.

---

## R√©sum√© des Performances par Objectif

### BO1 : Pr√©diction du Classement Final (MAE - plus bas = meilleur)
| Algorithme | MAE | Rang |
|------------|-----|------|
| **Random Forest** | **0.20** | ü•á |
| **XGBoost** | 1.12 | ü•à |
| **KNN** | 1.27 | ü•â |
| **Gradient Boosting** | 1.62 | 4 |

### BO2 : Pr√©diction Vainqueur de Match (Accuracy - plus haut = meilleur)
| Algorithme | Accuracy | Rang |
|------------|----------|------|
| **SVM (RBF)** | *√Ä √©valuer* | - |
| **Random Forest** | *√Ä √©valuer* | - |
| **XGBoost** | *√Ä √©valuer* | - |
| **KNN** | *√Ä √©valuer* | - |

### BO3 : Qualification Champions League Top 4 (F1-Score - plus haut = meilleur)
| Algorithme | F1-Score | Pr√©cision | Rappel | Rang |
|------------|----------|-----------|--------|------|
| **SVM** | *√Ä √©valuer* | - | - | - |
| **Random Forest** | *√Ä √©valuer* | - | - | - |
| **XGBoost** | *√Ä √©valuer* | - | - | - |
| **Gradient Boosting** | *√Ä √©valuer* | - | - | - |

---

## Analyse D√©taill√©e par Algorithme

### 1Ô∏è‚É£ Random Forest ‚Äî Champion de la Pr√©cision üèÜ

**Performance** :
- MAE : **0.20 positions** (meilleur r√©sultat)
- R¬≤ : **0.95** (excellente explication de variance)
- **100%** des pr√©dictions √† ¬±1 position
- **80%** de pr√©dictions parfaites (16/20 √©quipes)
- Champion 2024-25 correctement pr√©dit : Liverpool ‚úÖ

**Forces** :
- ‚úÖ Pr√©cision exceptionnelle gr√¢ce √† l'ensemble d'arbres
- ‚úÖ Robuste au surapprentissage via bootstrap
- ‚úÖ G√®re bien les interactions non-lin√©aires
- ‚úÖ Entra√Ænement rapide (~5 min pour 1 296 combinaisons)

**Faiblesses** :
- ‚ö†Ô∏è Moins interpr√©table qu'un arbre unique
- ‚ö†Ô∏è N√©cessite optimisation des hyperparam√®tres

**Cas d'usage id√©al** : Production ‚Äì pr√©dictions fiables pour analyses strat√©giques et paris sportifs

---

### 2Ô∏è‚É£ XGBoost ‚Äî R√©gularisation Puissante ‚ö°

**Performance** :
- MAE : **1.12 positions** (test), **0.22** (train)
- R¬≤ : **0.95** (test), **0.998** (train)
- **90%** √† ¬±2 positions, **45%** √† ¬±1 position
- MAE 2024-25 : **0.40** (12/20 pr√©dictions parfaites)

**Forces** :
- ‚úÖ Gradient boosting avec forte r√©gularisation (L1, L2, structurelle)
- ‚úÖ Excellent compromis biais-variance
- ‚úÖ G√®re naturellement les valeurs manquantes
- ‚úÖ Importance des variables tr√®s d√©taill√©e (Gain + Weight)

**Faiblesses** :
- ‚ö†Ô∏è Sensible aux hyperparam√®tres
- ‚ö†Ô∏è N√©cessite calibration minutieuse

**Cas d'usage id√©al** : Comp√©titions de machine learning, optimisation de performance maximale

---

### 3Ô∏è‚É£ SVM ‚Äî Sp√©cialiste Rel√©gation üî¥

**Performance** :
- MAE globale : 1.23 positions
- Classification binaire (rel√©gation) : **100%** pr√©cision, rappel, F1-score
- ROC AUC : **1.000** (discrimination parfaite)
- Zone de rel√©gation : MAE ~3.26 positions

**Forces** :
- ‚úÖ **100% de d√©tection des √©quipes rel√©gu√©es** (positions 18-20)
- ‚úÖ Noyau RBF capture relations complexes
- ‚úÖ Probabilit√©s calibr√©es pour √©valuation des risques
- ‚úÖ Seuil optimal trouv√© via maximisation F1

**Faiblesses** :
- ‚ö†Ô∏è Moins pr√©cis pour positions m√©dianes (milieu de tableau)
- ‚ö†Ô∏è Co√ªteux en calcul pour grands ensembles

**Cas d'usage id√©al** : Syst√®mes d'alerte pr√©coce pour clubs en difficult√©, √©valuation des risques financiers

---

### 4Ô∏è‚É£ KNN ‚Äî Apprentissage par Proximit√© üéØ

**Performance** :
- MAE : **1.27 positions**
- R¬≤ : **0.919**
- **80%** √† ¬±2 positions
- **58%** √† ¬±1 position

**Forces** :
- ‚úÖ Simplicit√© conceptuelle (bas√© sur similarit√©)
- ‚úÖ Pas d'hypoth√®ses sur distribution des donn√©es
- ‚úÖ Adaptable (k=7 optimal trouv√© par validation crois√©e)
- ‚úÖ Utile pour pr√©dictions en cours de saison

**Faiblesses** :
- ‚ö†Ô∏è Sensible √† l'√©chelle des variables (n√©cessite normalisation)
- ‚ö†Ô∏è Lent en pr√©diction sur grands ensembles
- ‚ö†Ô∏è Performance d√©grad√©e en haute dimension

**Cas d'usage id√©al** : Comparaisons rapides entre √©quipes, benchmarking de performances

---

### 5Ô∏è‚É£ Decision Tree ‚Äî Transparence D√©cisionnelle üå≥

**Performance** :
- MAE : **1.5 √† 2.5** positions (selon profondeur)
- R¬≤ : **0.85 √† 0.92**
- **55-65%** √† ¬±1 position
- **75-85%** √† ¬±2 positions

**Forces** :
- ‚úÖ **Tr√®s interpr√©table** ‚Äì r√®gles if/then claires
- ‚úÖ Visualisation des chemins de d√©cision
- ‚úÖ G√®re naturellement interactions et non-lin√©arit√©s
- ‚úÖ Pas de normalisation n√©cessaire

**Faiblesses** :
- ‚ö†Ô∏è Tendance au surapprentissage sans √©lagage
- ‚ö†Ô∏è Instable (petites variations ‚Üí arbres diff√©rents)
- ‚ö†Ô∏è Moins pr√©cis que m√©thodes ensemblistes

**Cas d'usage id√©al** : Rapports pour direction sportive, aide √† la d√©cision explicable

---

### 6Ô∏è‚É£ Gradient Boosting (LightGBM) ‚Äî Correction S√©quentielle üîß

**Performance** :
- MAE : **1.62 positions**
- RMSE : **2.01**
- **72%** √† ¬±2 positions
- **58%** √† ¬±1 position
- **38%** de positions exactes

**Forces** :
- ‚úÖ Correction s√©quentielle des erreurs r√©siduelles
- ‚úÖ Entra√Ænement rapide avec LightGBM
- ‚úÖ Early stopping automatique (meilleure it√©ration trouv√©e)
- ‚úÖ Bon compromis pr√©cision/vitesse

**Faiblesses** :
- ‚ö†Ô∏è N√©cessite tuning minutieux (learning rate, num_leaves)
- ‚ö†Ô∏è Risque de surapprentissage si mal calibr√©

**Cas d'usage id√©al** : Pipelines automatis√©s, pr√©dictions en temps r√©el

---

## Variables les Plus Importantes (Toutes M√©thodes Confondues)

**Top 5 Facteurs Pr√©dictifs** :

1. **Diff√©rence de buts (Goal Difference)** ‚Äì Indicateur #1 de performance
2. **Points totaux / Points par match** ‚Äì R√©sultat direct des victoires
3. **Taux de victoires (Win Rate)** ‚Äì Constance dans les r√©sultats
4. **Buts marqu√©s / Buts encaiss√©s** ‚Äì Efficacit√© offensive et d√©fensive
5. **Clean sheets (matches sans but encaiss√©)** ‚Äì Solidit√© d√©fensive

**Facteurs Secondaires** :
- Pr√©cision des tirs (Shot Accuracy)
- Performance domicile vs ext√©rieur (Home/Away Win Rate)
- Encodages d'√©quipe et saison (force historique, tendances temporelles)

---

## Recommandations par Cas d'Usage

| Besoin | Algorithme Recommand√© | Raison |
|--------|----------------------|---------|
| **Pr√©diction finale de saison** | Random Forest | Pr√©cision maximale (MAE 0.20) |
| **Pr√©diction issue de match** | Random Forest | Capacit√© de classification (Win/Draw/Loss) |
| **D√©tection risque de rel√©gation** | SVM | 100% de d√©tection, ROC AUC parfait |
| **Analyse explicable pour direction** | Decision Tree | R√®gles claires et visualisables |
| **Pipeline production haute performance** | XGBoost | R√©gularisation robuste, excellent R¬≤ |
| **Comparaison rapide entre √©quipes** | KNN | Similarit√© intuitive, pas de r√©entra√Ænement |
| **Syst√®me temps r√©el avec mise √† jour** | Gradient Boosting | Rapide, adaptatif |

---

## Conclusions Cl√©s

### ‚úÖ Tous les algorithmes satisfont leurs objectifs m√©tier

- **Random Forest** : Meilleure pr√©cision globale ‚Üí id√©al pour pr√©dictions finales
- **XGBoost** : Meilleur compromis performance/r√©gularisation
- **SVM** : Champion de la d√©tection de rel√©gation (100% pr√©cision)
- **KNN, Decision Tree, Gradient Boosting** : Compl√©mentaires selon le contexte

### üìä Enseignements G√©n√©raux

1. **Les m√©thodes ensemblistes dominent** (Random Forest, XGBoost) avec MAE < 1.5
2. **La diff√©rence de buts est le pr√©dicteur #1** dans tous les mod√®les
3. **25 saisons de donn√©es suffisent** pour des pr√©dictions fiables
4. **La r√©gularisation est cruciale** (XGBoost) pour √©viter le surapprentissage
5. **L'interpr√©tabilit√© a un co√ªt** : Decision Tree moins pr√©cis mais plus explicable

### üéØ Strat√©gie Optimale

**Approche hybride recommand√©e** :
1. **Random Forest** pour pr√©diction finale (MAE 0.20)
2. **SVM** pour alertes rel√©gation (100% d√©tection)
3. **Decision Tree** pour rapports direction (interpr√©tabilit√©)

---

**Date de cr√©ation** : Novembre 2025  
**Projet** : Pr√©diction Classements Premier League 
**Repository** : [pl-standings-prediction-project](https://github.com/AtfastrSlushyMaker/pl-standings-prediction-project)
