{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a694729"
      },
      "source": [
        "## 1. CONFIGURATION & IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkIlyi6UjbEp",
        "outputId": "f8290ef4-e792-4e03-c389-3468ca1bcef6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Configuration display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 150)\n",
        "\n",
        "\n",
        "# Styles graphiques\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"\\U0001f3c6 PREMIER LEAGUE PLAYER PERFORMANCE DATA PREPARATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\ud83d\\uddd3 Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez4GUZUcjzeD"
      },
      "source": [
        "## 2. PATH CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CaNQWE9Zqjv",
        "outputId": "91399436-7e87-4a8c-9610-c48d6c3cc1ce"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if the zip file exists and unzip it if the directory doesn't exist\n",
        "zip_path = Path('/content/player_performance.zip')\n",
        "expected_dir = Path('/content/player_performance')\n",
        "\n",
        "if zip_path.exists() and not expected_dir.exists():\n",
        "    print(f\"üì¶ Unzipping {zip_path.name} to {expected_dir}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(expected_dir.parent) # extracts to /content/\n",
        "    print(\"‚úÖ Unzipping complete.\")\n",
        "elif expected_dir.exists():\n",
        "    print(f\"üìÅ Directory {expected_dir} already exists. Skipping unzipping.\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è {zip_path.name} not found. Ensure it's uploaded if needed.\")\n",
        "\n",
        "\n",
        "# Candidate paths: local or relative to Colab's mounted drive\n",
        "candidate_paths = [\n",
        "    Path('data/player_performance'),\n",
        "    Path('../data/player_performance'),\n",
        "    Path('../../data/player_performance'),\n",
        "    Path('/content/player_performance'),  \n",
        "    Path(\"data/player_performance\"),\n",
        "    Path(\"raw/player_performance\"),\n",
        "    Path(\"raw/uncombined/player_performance\"),\n",
        "    Path('/content/drive/MyDrive/pl-standings-prediction-project/data/player_performance')  \n",
        "]\n",
        "\n",
        "# Try to find the valid path\n",
        "data_path = next((p for p in candidate_paths if p.exists()), None)\n",
        "\n",
        "if data_path is None:\n",
        "    raise FileNotFoundError('‚ùå player_performance folder not found in expected locations.\\n'\n",
        "                            'Checked: ' + ', '.join(str(p) for p in candidate_paths))\n",
        "\n",
        "print(f\"‚úÖ Found data directory at: {data_path.resolve()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkEnXajXkDY7"
      },
      "source": [
        "## 3. LOAD ALL SEASON CSV FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TghpW_lzaVH1",
        "outputId": "71f849a1-5212-4e47-ab6b-03b774c864cd"
      },
      "outputs": [],
      "source": [
        "seasons = [\n",
        "    '2016-17', '2017-18', '2018-19', '2019-20', '2020-21',\n",
        "    '2021-22', '2022-23', '2023-24', '2024-25', '2025-26'\n",
        "]\n",
        "\n",
        "\n",
        "all_seasons_data = []\n",
        "loading_summary = []\n",
        "\n",
        "\n",
        "for season in seasons:\n",
        "    file_path = data_path / season / 'cleaned_players.csv'\n",
        "    try:\n",
        "        # Attempt to read with 'utf-8', then 'latin-1' if utf-8 fails\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            df = pd.read_csv(file_path, encoding='latin-1')\n",
        "\n",
        "        df['season'] = season\n",
        "        all_seasons_data.append(df)\n",
        "        loading_summary.append({'season': season, 'players': len(df), 'status': '‚úÖ Success'})\n",
        "        print(f\"‚úÖ {season}: {len(df):>4} players loaded\")\n",
        "    except FileNotFoundError:\n",
        "        loading_summary.append({'season': season, 'players': 0, 'status': '‚ùå File not found'})\n",
        "        print(f\"‚ùå {season}: File not found\")\n",
        "    except Exception as e:\n",
        "        loading_summary.append({'season': season, 'players': 0, 'status': f'‚ùå Error: {str(e)}'})\n",
        "        print(f\"‚ùå {season}: Error - {e}\")\n",
        "\n",
        "\n",
        "if all_seasons_data:\n",
        "    df_combined = pd.concat(all_seasons_data, ignore_index=True)\n",
        "    print(f\"\\nüéØ TOTAL COMBINED ROWS: {len(df_combined):,}\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå No data loaded\")\n",
        "\n",
        "\n",
        "summary_df = pd.DataFrame(loading_summary)\n",
        "print(\"\\nüìä LOAD SUMMARY:\")\n",
        "print(summary_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwafHpZkVii"
      },
      "source": [
        "## 4. INITIAL DATA INSPECTION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fGD4gRplsoM",
        "outputId": "1588ea61-491f-4733-91fc-cc42ddd93020"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üîç STEP 4: INITIAL DATA INSPECTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüìä Data shape: {df_combined.shape}\")\n",
        "print(f\"   ‚Ä¢ Rows   : {df_combined.shape[0]:,}\")\n",
        "print(f\"   ‚Ä¢ Columns: {df_combined.shape[1]}\")\n",
        "\n",
        "print(f\"\\nüìÖ Seasons covered: {df_combined['season'].nunique()}\")\n",
        "print(f\"   {sorted(df_combined['season'].unique())}\")\n",
        "\n",
        "# Detect available name columns\n",
        "name_cols = [col for col in df_combined.columns if 'name' in col.lower()]\n",
        "\n",
        "print(\"\\nüë• Player name columns detected:\", name_cols)\n",
        "\n",
        "# Display unique players based on best available name column\n",
        "if 'player_name' in df_combined.columns:\n",
        "    print(f\"üë• Unique players (player_name): {df_combined['player_name'].nunique():,}\")\n",
        "elif 'second_name' in df_combined.columns:\n",
        "    print(f\"üë• Unique players (second_name): {df_combined['second_name'].nunique():,}\")\n",
        "elif 'first_name' in df_combined.columns:\n",
        "    print(f\"üë• Unique players (first_name): {df_combined['first_name'].nunique():,}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No player name column found for uniqueness count.\")\n",
        "\n",
        "print(\"\\nüìã Available columns:\")\n",
        "for i, col in enumerate(df_combined.columns, 1):\n",
        "    print(f\"   {i:2d}. {col}\")\n",
        "\n",
        "print(\"\\nüîé Sample preview (first 3 rows):\")\n",
        "print(df_combined.head(3))\n",
        "\n",
        "print(\"\\nüìà Data types overview (count by dtype):\")\n",
        "print(df_combined.dtypes.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GgRSKL4l9AT"
      },
      "source": [
        "## 5. MISSING VALUE ANALYSIS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "ieLEE7wvl_61",
        "outputId": "11be30fc-bc5d-4069-94fb-3911b8a02088"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üîç STEP 5: MISSING VALUE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Prevent division by zero in case dataframe is empty\n",
        "if len(df_combined) == 0:\n",
        "    print(\"‚ö†Ô∏è Dataset is empty. Missing value analysis skipped.\")\n",
        "else:\n",
        "    # Build missing values table\n",
        "    missing_analysis = pd.DataFrame({\n",
        "        'column': df_combined.columns,\n",
        "        'missing_count': df_combined.isnull().sum(),\n",
        "        'missing_percent': (df_combined.isnull().sum() / len(df_combined) * 100).round(2)\n",
        "    })\n",
        "\n",
        "    # Keep only columns with missing values\n",
        "    missing_analysis = (\n",
        "        missing_analysis[missing_analysis['missing_count'] > 0]\n",
        "        .sort_values('missing_percent', ascending=False)\n",
        "    )\n",
        "\n",
        "    if len(missing_analysis) > 0:\n",
        "        print(\"\\n‚ö†Ô∏è Columns with missing values detected:\")\n",
        "        print(missing_analysis.to_string(index=False))\n",
        "\n",
        "        # Visualization: Missing percentage bar chart\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(missing_analysis['column'], missing_analysis['missing_percent'])\n",
        "        plt.xlabel('Missing values (%)')\n",
        "        plt.title('Missing values by column')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No missing values detected in the dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuTVSRsFmGip"
      },
      "source": [
        "## 6. COLUMN SELECTION (PLAYER PERFORMANCE FOCUS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBBw65xz0yi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lv-p7xXmKK-",
        "outputId": "9a7b9152-8a36-4206-e113-1164167bc723"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üéØ STEP 6: SELECT RELEVANT COLUMNS FOR PLAYER PERFORMANCE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# -----------------------------\n",
        "# Define the columns you want\n",
        "# -----------------------------\n",
        "selected_columns = {\n",
        "    \"identity\": [\"first_name\", \"second_name\"],\n",
        "    \"context\": [\"season\"],   #\n",
        "    \"value\": [\"now_cost\", \"selected_by_percent\"],\n",
        "    \"performance\": [\"total_points\", \"points_per_game\", \"form\", \"minutes\"],\n",
        "    \"offensive\": [\"goals_scored\", \"assists\", \"creativity\", \"threat\"],\n",
        "    \"defensive\": [\"clean_sheets\", \"goals_conceded\", \"yellow_cards\", \"red_cards\"],\n",
        "    \"advanced\": [\"influence\", \"ict_index\", \"bonus\", \"bps\"]\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# Flatten the full list\n",
        "# -----------------------------\n",
        "all_selected = []\n",
        "for cols in selected_columns.values():\n",
        "    all_selected.extend(cols)\n",
        "\n",
        "# -----------------------------\n",
        "# Keep only columns that exist\n",
        "# -----------------------------\n",
        "available_columns = [c for c in all_selected if c in df_combined.columns]\n",
        "missing_columns = [c for c in all_selected if c not in df_combined.columns]\n",
        "\n",
        "print(f\"\\n‚úÖ Selected columns found: {len(available_columns)}/{len(all_selected)}\")\n",
        "\n",
        "if missing_columns:\n",
        "    print(\"\\n‚ö†Ô∏è Missing columns (ignored):\")\n",
        "    for col in missing_columns:\n",
        "        print(f\"   ‚Ä¢ {col}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Create df_selected\n",
        "# -----------------------------\n",
        "df_selected = df_combined[available_columns].copy()\n",
        "\n",
        "print(f\"\\nüìä Shape after selection: {df_selected.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjg-pRy9mdO0"
      },
      "source": [
        "## 7. DATA CLEANING & FILTERING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBqD3ylmcEk",
        "outputId": "4c91a041-2c81-41c2-bc8b-9da66039073d"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üßπ STEP 7: DATA CLEANING & FILTERING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "initial_rows = len(df_selected)\n",
        "\n",
        "# ============================================================\n",
        "# 7.1 HANDLE MISSING VALUES\n",
        "# ============================================================\n",
        "print(\"\\nüìù Handling missing values...\")\n",
        "\n",
        "# Numeric columns ‚Üí fill NaN with 0\n",
        "numeric_cols = df_selected.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if df_selected[col].isnull().sum() > 0:\n",
        "        df_selected[col] = df_selected[col].fillna(0)\n",
        "        print(f\"   ‚Ä¢ {col}: filled NaN with 0\")\n",
        "\n",
        "# Text columns ‚Üí fill NaN with \"Unknown\"\n",
        "text_cols = df_selected.select_dtypes(include=['object']).columns\n",
        "for col in text_cols:\n",
        "    if df_selected[col].isnull().sum() > 0:\n",
        "        df_selected[col] = df_selected[col].fillna(\"Unknown\")\n",
        "        print(f\"   ‚Ä¢ {col}: filled NaN with 'Unknown'\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7.1.1 DROP USELESS COLUMNS\n",
        "# ============================================================\n",
        "print(\"\\nüóëÔ∏è Dropping useless columns...\")\n",
        "\n",
        "missing_threshold = 0.90\n",
        "cols_to_drop = []\n",
        "\n",
        "for col in df_selected.columns:\n",
        "    # NEVER drop these essential columns\n",
        "    if col in ['first_name', 'second_name', 'season', 'minutes', 'total_points']:\n",
        "        continue\n",
        "\n",
        "    miss = df_selected[col].isnull().mean()\n",
        "    uniq = df_selected[col].nunique(dropna=True)\n",
        "\n",
        "    if miss > missing_threshold or uniq <= 1:\n",
        "        cols_to_drop.append(col)\n",
        "\n",
        "if cols_to_drop:\n",
        "    df_selected.drop(columns=cols_to_drop, inplace=True)\n",
        "    print(f\"   ‚Ä¢ Dropped: {cols_to_drop}\")\n",
        "else:\n",
        "    print(\"   ‚Ä¢ No columns dropped\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7.2 FILTER BY MINUTES PLAYED\n",
        "# ============================================================\n",
        "print(\"\\n‚è±Ô∏è Filtering players by minutes ‚â• 90...\")\n",
        "\n",
        "min_minutes = 90\n",
        "df_filtered = df_selected[df_selected['minutes'] >= min_minutes].copy()\n",
        "\n",
        "filtered_out = initial_rows - len(df_filtered)\n",
        "\n",
        "print(f\"   ‚Ä¢ Players kept       : {len(df_filtered)}\")\n",
        "print(f\"   ‚Ä¢ Players filtered   : {filtered_out} ({filtered_out/initial_rows*100:.1f}%)\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7.3 REMOVE DUPLICATES (by first + second name + season)\n",
        "# ============================================================\n",
        "print(\"\\nüîÑ Removing duplicates...\")\n",
        "\n",
        "df_filtered['_temp_player_name'] = (\n",
        "    df_filtered['first_name'].astype(str) + \" \" + df_filtered['second_name'].astype(str)\n",
        ").str.strip()\n",
        "\n",
        "dups = df_filtered.duplicated(subset=['_temp_player_name', 'season']).sum()\n",
        "\n",
        "if dups > 0:\n",
        "    print(f\"   ‚Ä¢ Removed {dups} duplicate rows\")\n",
        "    df_filtered = df_filtered.drop_duplicates(subset=['_temp_player_name', 'season'])\n",
        "else:\n",
        "    print(\"   ‚Ä¢ No duplicates found\")\n",
        "\n",
        "df_filtered.drop(columns=['_temp_player_name'], inplace=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Final shape after cleaning: {df_filtered.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# No POSITION column created (because no element_type)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n‚ÑπÔ∏è No 'position' column generated (no element_type in dataset).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H445SQ_2m3t3"
      },
      "source": [
        "##8. DERIVED FEATURE CREATION (PLAYER PERFORMANCE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPaAvhUam7d1",
        "outputId": "8b420d52-111a-4fc8-d466-e0aaf75d400c"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚öôÔ∏è STEP 8: DERIVED FEATURE CREATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df_enriched = df_filtered.copy()\n",
        "\n",
        "# ============================================================\n",
        "# Avoid division by zero\n",
        "# ============================================================\n",
        "if 'minutes' in df_enriched.columns:\n",
        "    matches = (df_enriched['minutes'] / 90).replace(0, np.nan)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è 'minutes' column missing ‚Äî cannot compute per-90 metrics.\")\n",
        "    matches = None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Offensive metrics\n",
        "# ============================================================\n",
        "if matches is not None and 'goals_scored' in df_enriched.columns:\n",
        "    df_enriched['goals_per_90'] = (df_enriched['goals_scored'] / matches).round(3)\n",
        "    print(\"   ‚Ä¢ goals_per_90 created\")\n",
        "\n",
        "if matches is not None and 'assists' in df_enriched.columns:\n",
        "    df_enriched['assists_per_90'] = (df_enriched['assists'] / matches).round(3)\n",
        "    print(\"   ‚Ä¢ assists_per_90 created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Goal involvement\n",
        "# ============================================================\n",
        "if all(col in df_enriched.columns for col in ['goals_scored', 'assists']):\n",
        "    df_enriched['goal_involvement'] = (\n",
        "        df_enriched['goals_scored'] + df_enriched['assists']\n",
        "    )\n",
        "    df_enriched['goal_involvement_per_90'] = (\n",
        "        df_enriched['goal_involvement'] / matches\n",
        "    ).round(3)\n",
        "    print(\"   ‚Ä¢ goal_involvement & goal_involvement_per_90 created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Defensive metrics\n",
        "# ============================================================\n",
        "if matches is not None and 'clean_sheets' in df_enriched.columns:\n",
        "    df_enriched['clean_sheet_rate'] = (df_enriched['clean_sheets'] / matches).round(3)\n",
        "    print(\"   ‚Ä¢ clean_sheet_rate created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Discipline metrics\n",
        "# ============================================================\n",
        "if all(col in df_enriched.columns for col in ['yellow_cards', 'red_cards']):\n",
        "    df_enriched['total_cards'] = (\n",
        "        df_enriched['yellow_cards'] + df_enriched['red_cards'] * 2\n",
        "    )\n",
        "    df_enriched['cards_per_90'] = (\n",
        "        df_enriched['total_cards'] / matches\n",
        "    ).round(3)\n",
        "    print(\"   ‚Ä¢ total_cards & cards_per_90 created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Efficiency: points_per_cost\n",
        "# ============================================================\n",
        "if all(col in df_enriched.columns for col in ['total_points', 'now_cost']):\n",
        "    df_enriched['points_per_cost'] = (\n",
        "        df_enriched['total_points'] / df_enriched['now_cost']\n",
        "    ).replace([np.inf, -np.inf], 0).round(3)\n",
        "    print(\"   ‚Ä¢ points_per_cost created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Ranking per season\n",
        "# ============================================================\n",
        "if all(col in df_enriched.columns for col in ['total_points', 'season']):\n",
        "    df_enriched['rank_in_season'] = (\n",
        "        df_enriched.groupby('season')['total_points']\n",
        "        .rank(method='min', ascending=False)\n",
        "        .astype(int)\n",
        "    )\n",
        "    print(\"   ‚Ä¢ rank_in_season created\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Final output\n",
        "# ============================================================\n",
        "print(f\"\\nüìä Final shape after feature engineering: {df_enriched.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS6TijKFnOq4"
      },
      "source": [
        "##9. ENCODING CATEGORICAL VARIABLES\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpXx7XFynUJK",
        "outputId": "54e30444-b8a1-4851-fe0c-54a82b330210"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üî§ STEP 9: ENCODING CATEGORICAL VARIABLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df_encoded = df_enriched.copy()\n",
        "\n",
        "# ============================================================\n",
        "# 1. Encode categorical columns (only those that exist)\n",
        "# ============================================================\n",
        "categorical_cols = ['season']   # no 'position' in your dataset\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in df_encoded.columns:\n",
        "        df_encoded[col] = df_encoded[col].astype('category')\n",
        "        df_encoded[f\"{col}_encoded\"] = df_encoded[col].cat.codes\n",
        "        print(f\"   ‚Ä¢ Encoded '{col}' ‚Üí '{col}_encoded'\")\n",
        "    else:\n",
        "        print(f\"   ‚Ä¢ Skipped '{col}' (column not found)\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Create unified player_name field\n",
        "# ============================================================\n",
        "has_first = 'first_name' in df_encoded.columns\n",
        "has_second = 'second_name' in df_encoded.columns\n",
        "\n",
        "if has_first and has_second:\n",
        "    df_encoded['player_name'] = (\n",
        "        df_encoded['first_name'].astype(str) + \" \" + df_encoded['second_name'].astype(str)\n",
        "    ).str.strip()\n",
        "elif has_second:\n",
        "    df_encoded['player_name'] = df_encoded['second_name'].astype(str)\n",
        "elif has_first:\n",
        "    df_encoded['player_name'] = df_encoded['first_name'].astype(str)\n",
        "else:\n",
        "    df_encoded['player_name'] = \"Unknown Player\"\n",
        "\n",
        "df_encoded['player_name'] = df_encoded['player_name'].replace('', 'Unknown Player')\n",
        "\n",
        "print(\"   ‚Ä¢ 'player_name' column created.\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Summary\n",
        "# ============================================================\n",
        "print(\"\\n‚úÖ Encoding complete.\")\n",
        "print(\"üìä Shape:\", df_encoded.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9JLHeKwnfGg"
      },
      "source": [
        "##10. DESCRIPTIVE STATISTICS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8slZNxmnhZg",
        "outputId": "e94c6a7c-3a9f-4d1c-ae9f-30b97b0e1580"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìà STEP 10: DESCRIPTIVE STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# NUMERIC METRICS SUMMARY\n",
        "# ---------------------------------------------------------\n",
        "metrics = ['total_points', 'goals_scored', 'assists', 'clean_sheets', 'minutes']\n",
        "available = [m for m in metrics if m in df_encoded.columns]\n",
        "\n",
        "if available:\n",
        "    print(\"\\nüìä Key metrics:\")\n",
        "    print(df_encoded[available].describe().round(2))\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No performance metrics found.\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# SEASON DISTRIBUTION\n",
        "# ---------------------------------------------------------\n",
        "if 'season' in df_encoded.columns:\n",
        "    print(\"\\nüìÖ Season distribution:\")\n",
        "    print(df_encoded['season'].value_counts().sort_index())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è 'season' column missing.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAlXUpmFotVK"
      },
      "source": [
        "## 11. EXPLORATORY VISUALISATIONS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vKe4m1Eooxjh",
        "outputId": "dc376c41-f950-48d8-8a2d-728d6b648e3f"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä STEP 11: EXPLORATORY VISUALISATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 11.1 Average Total Points Per Season\n",
        "# ============================================================\n",
        "\n",
        "if 'season' in df_encoded.columns and 'total_points' in df_encoded.columns:\n",
        "    avg = df_encoded.groupby('season')['total_points'].mean()\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    avg.plot(kind='bar', color='coral', edgecolor='black')\n",
        "    plt.title(\"Average Total Points per Season\")\n",
        "    plt.xlabel(\"Season\")\n",
        "    plt.ylabel(\"Average Points\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Missing 'season' or 'total_points' ‚Üí cannot compute seasonal averages.\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 11.2 Correlation Matrix\n",
        "# ============================================================\n",
        "\n",
        "corr_features = ['total_points','goals_scored','assists','clean_sheets','minutes']\n",
        "corr_available = [c for c in corr_features if c in df_encoded.columns]\n",
        "\n",
        "if len(corr_available) >= 2:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(df_encoded[corr_available].corr(),\n",
        "                annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title(\"Correlation Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Not enough numeric features for correlation matrix.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg8TI3wEo_SP"
      },
      "source": [
        "## 12. IDENTIFYING TOP PERFORMERS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_4VmkkQpB6z",
        "outputId": "6b6dc897-f551-4c65-9f1c-1af99874aded"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üèÜ STEP 12: IDENTIFYING TOP PERFORMERS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================\n",
        "# 1. CREATE PLAYER NAME COLUMN (first + second name)\n",
        "# ============================================================\n",
        "\n",
        "first = 'first_name' in df_encoded.columns\n",
        "second = 'second_name' in df_encoded.columns\n",
        "\n",
        "if first and second:\n",
        "    df_encoded['player_name'] = (\n",
        "        df_encoded['first_name'].astype(str) + \" \" +\n",
        "        df_encoded['second_name'].astype(str)\n",
        "    ).str.strip()\n",
        "elif second:\n",
        "    df_encoded['player_name'] = df_encoded['second_name'].astype(str)\n",
        "elif first:\n",
        "    df_encoded['player_name'] = df_encoded['first_name'].astype(str)\n",
        "else:\n",
        "    df_encoded['player_name'] = \"Unknown Player\"\n",
        "\n",
        "df_encoded['player_name'] = df_encoded['player_name'].replace(\"\", \"Unknown Player\")\n",
        "\n",
        "print(\"üéØ Player name column created.\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. TOP 50 PER SEASON\n",
        "# ============================================================\n",
        "\n",
        "top_performers_list = []\n",
        "\n",
        "if 'season' in df_encoded.columns and 'total_points' in df_encoded.columns:\n",
        "\n",
        "    for season in sorted(df_encoded['season'].unique()):\n",
        "        season_data = df_encoded[df_encoded['season'] == season]\n",
        "        top_50 = season_data.nlargest(50, 'total_points')\n",
        "        top_performers_list.append(top_50)\n",
        "\n",
        "    df_top_performers = pd.concat(top_performers_list, ignore_index=True)\n",
        "\n",
        "    print(f\"\\n‚úÖ Top 50 players extracted for each season.\")\n",
        "    print(f\"üìä Total records in top_performers dataset: {len(df_top_performers):,}\")\n",
        "\n",
        "    # Preview for user\n",
        "    print(\"\\nüëÄ SAMPLE: Top 5 per season (player_name + points):\")\n",
        "    for season in sorted(df_top_performers['season'].unique()):\n",
        "        season_top_5 = (\n",
        "            df_top_performers[df_top_performers['season'] == season]\n",
        "            .nlargest(5, 'total_points')\n",
        "        )\n",
        "\n",
        "        preview_cols = ['player_name', 'season', 'total_points', 'goals_scored', 'assists']\n",
        "        preview_cols = [c for c in preview_cols if c in season_top_5.columns]\n",
        "\n",
        "        print(f\"\\n‚Äî Season {season} ‚Äî\")\n",
        "        print(season_top_5[preview_cols].to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Missing 'season' or 'total_points' ‚Äî cannot compute top performers.\")\n",
        "    df_top_performers = pd.DataFrame()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. GLOBAL TOP 10\n",
        "# ============================================================\n",
        "\n",
        "if 'total_points' in df_encoded.columns and not df_encoded.empty:\n",
        "\n",
        "    print(\"\\nü•á GLOBAL TOP 10 PLAYERS (by total_points):\")\n",
        "\n",
        "    # Only columns that actually exist\n",
        "    columns_to_display = [\n",
        "        'player_name', 'season',\n",
        "        'total_points', 'goals_scored', 'assists', 'minutes'\n",
        "    ]\n",
        "    columns_to_display = [c for c in columns_to_display if c in df_encoded.columns]\n",
        "\n",
        "    top_10_global = df_encoded.nlargest(10, 'total_points')[columns_to_display]\n",
        "\n",
        "    print(top_10_global.to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot compute global top 10 ‚Äî missing 'total_points'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdXm9XcI75it",
        "outputId": "13916034-5282-4671-bcf4-727978817371"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìÅ DATASET AFTER FULL CLEANING & PROCESSING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(df_encoded.head(20))\n",
        "print(\"\\nShape:\", df_encoded.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9o5ZBkmpLzn"
      },
      "source": [
        "## 13. PRINCIPAL COMPONENT ANALYSIS (PCA) FOR PLAYER PERFORMANCE DATA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bnuGJJH_xT77",
        "outputId": "a946c639-5799-491c-d878-42db5442bfec"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üî¨ STEP 12.5: PRINCIPAL COMPONENT ANALYSIS (PCA)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1. Select numerical features for PCA\n",
        "# ----------------------------------------------------------\n",
        "# Exclude encoded categorical variables (if they exist)\n",
        "exclude_cols = ['season_encoded', 'team_encoded', 'position_encoded']\n",
        "\n",
        "numeric_df = df_encoded.select_dtypes(include=[np.number]).copy()\n",
        "numeric_df = numeric_df[[c for c in numeric_df.columns if c not in exclude_cols]]\n",
        "\n",
        "print(f\"üìä Numeric features available for PCA: {numeric_df.shape[1]}\")\n",
        "\n",
        "# Drop rows with NaN values for PCA stability\n",
        "numeric_df_clean = numeric_df.dropna()\n",
        "\n",
        "if numeric_df_clean.shape[0] < 2:\n",
        "    print(\"\\n‚ö†Ô∏è Not enough valid rows for PCA. Skipping PCA step.\")\n",
        "else:\n",
        "    # ------------------------------------------------------\n",
        "    # 2. Standardization\n",
        "    # ------------------------------------------------------\n",
        "    scaler = StandardScaler()\n",
        "    numeric_scaled = scaler.fit_transform(numeric_df_clean)\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 3. PCA computation\n",
        "    # ------------------------------------------------------\n",
        "    pca = PCA()\n",
        "    pca_components = pca.fit_transform(numeric_scaled)\n",
        "    explained_var = pca.explained_variance_ratio_\n",
        "\n",
        "    print(\"\\nüìà Variance explained by first components:\")\n",
        "    for i, var in enumerate(explained_var[:5]):\n",
        "        print(f\"   PC{i+1}: {var*100:.2f}%\")\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 4. Scree plot\n",
        "    # ------------------------------------------------------\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(explained_var)+1), explained_var, marker='o')\n",
        "    plt.xlabel(\"Principal Component\")\n",
        "    plt.ylabel(\"Variance Explained\")\n",
        "    plt.title(\"Scree Plot: PCA Variance Explained\")\n",
        "    plt.grid(alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 5. Cumulative explained variance\n",
        "    # ------------------------------------------------------\n",
        "    cumulative_var = explained_var.cumsum()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(explained_var)+1), cumulative_var, marker='o')\n",
        "    plt.xlabel(\"Principal Component\")\n",
        "    plt.ylabel(\"Cumulative Variance Explained\")\n",
        "    plt.title(\"Cumulative Explained Variance\")\n",
        "    plt.grid(alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 6. PCA projection dataframe (PC1 & PC2)\n",
        "    # ------------------------------------------------------\n",
        "    pca_df = pd.DataFrame({\n",
        "        \"PC1\": pca_components[:, 0],\n",
        "        \"PC2\": pca_components[:, 1]\n",
        "    }, index=numeric_df_clean.index)\n",
        "\n",
        "    if 'player_name' in df_encoded.columns:\n",
        "        pca_df['player_name'] = df_encoded.loc[pca_df.index, 'player_name']\n",
        "\n",
        "    if 'season' in df_encoded.columns:\n",
        "        pca_df['season'] = df_encoded.loc[pca_df.index, 'season']\n",
        "\n",
        "    print(\"\\nüìä PCA projection dataframe sample:\")\n",
        "    print(pca_df.head())\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 7. Scatter plot PC1 vs PC2 (colored by season if available)\n",
        "    # ------------------------------------------------------\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    if 'season' in pca_df.columns:\n",
        "        sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"season\", palette=\"tab10\")\n",
        "    else:\n",
        "        sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\")\n",
        "    plt.title(\"Projection of Players on PC1 & PC2\")\n",
        "    plt.axhline(0, color='grey', linewidth=1)\n",
        "    plt.axvline(0, color='grey', linewidth=1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # 8. Correlation Circle (Cercle de corr√©lation)\n",
        "    #     (variables contributions on PC1 & PC2)\n",
        "    # ------------------------------------------------------\n",
        "    variables = numeric_df_clean.columns           # names of original numeric variables\n",
        "    pcs = pca.components_                          # eigenvectors matrix\n",
        "    x_vector = pcs[0, :]                           # loadings on PC1\n",
        "    y_vector = pcs[1, :]                           # loadings on PC2\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.axhline(0, color='grey', linestyle='--')\n",
        "    plt.axvline(0, color='grey', linestyle='--')\n",
        "\n",
        "    for i in range(len(variables)):\n",
        "        plt.arrow(0, 0,\n",
        "                  x_vector[i], y_vector[i],\n",
        "                  color='blue', alpha=0.5, head_width=0.02)\n",
        "        plt.text(x_vector[i]*1.1,\n",
        "                 y_vector[i]*1.1,\n",
        "                 variables[i],\n",
        "                 fontsize=9)\n",
        "\n",
        "    # unit circle\n",
        "    circle = plt.Circle((0, 0), 1, color='black', fill=False, linestyle='--')\n",
        "    plt.gca().add_artist(circle)\n",
        "\n",
        "    plt.xlim(-1, 1)\n",
        "    plt.ylim(-1, 1)\n",
        "    plt.grid(True)\n",
        "    plt.title(\"Correlation Circle (PC1 & PC2)\")\n",
        "    plt.xlabel(f\"PC1 ({explained_var[0]*100:.2f}% var.)\")\n",
        "    plt.ylabel(f\"PC2 ({explained_var[1]*100:.2f}% var.)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJqQHtz_xQ2W"
      },
      "source": [
        "## 13. SAVING PROCESSED DATASETS & METADATA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQGjht82tZp7",
        "outputId": "5a9718b4-0b73-4b3d-e460-8c5bab21c0c6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ STEP 13: SAVING PROCESSED DATASETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create output folder\n",
        "processed_path = Path(data_path) / 'processed'\n",
        "processed_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 13.1 Save FULL processed dataset\n",
        "# ------------------------------------------------------\n",
        "output_complete = processed_path / 'players_cleaned_complete.csv'\n",
        "df_encoded.to_csv(output_complete, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Full processed dataset saved:\")\n",
        "print(f\"   üìÅ {output_complete}\")\n",
        "print(f\"   üìä {df_encoded.shape[0]:,} rows √ó {df_encoded.shape[1]} columns\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 13.2 Save Top Performers dataset\n",
        "# ------------------------------------------------------\n",
        "if 'df_top_performers' in locals() and not df_top_performers.empty:\n",
        "    output_top = processed_path / 'players_top_performers.csv'\n",
        "    df_top_performers.to_csv(output_top, index=False)\n",
        "\n",
        "    print(f\"\\n‚úÖ Top performers saved:\")\n",
        "    print(f\"   üìÅ {output_top}\")\n",
        "    print(f\"   üìä {df_top_performers.shape[0]:,} rows\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Top performers dataset empty ‚Äî nothing saved.\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 13.3 Season-Level Statistics\n",
        "# ------------------------------------------------------\n",
        "if 'season' in df_encoded.columns:\n",
        "\n",
        "    agg_dict = {'player_name': 'count'}\n",
        "\n",
        "    for col in ['total_points', 'goals_scored', 'assists', 'minutes']:\n",
        "        if col in df_encoded.columns:\n",
        "            if col == 'total_points':\n",
        "                agg_dict[col] = ['mean', 'median', 'std', 'max']\n",
        "            else:\n",
        "                agg_dict[col] = 'sum'\n",
        "\n",
        "    season_summary = df_encoded.groupby('season').agg(agg_dict).round(2)\n",
        "\n",
        "    # Flatten MultiIndex\n",
        "    season_summary.columns = [\n",
        "        '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "        for col in season_summary.columns\n",
        "    ]\n",
        "\n",
        "    output_summary = processed_path / 'players_season_statistics.csv'\n",
        "    season_summary.to_csv(output_summary)\n",
        "\n",
        "    print(f\"\\n‚úÖ Season statistics saved:\")\n",
        "    print(f\"   üìÅ {output_summary}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 13.4 Save metadata (JSON)\n",
        "# ------------------------------------------------------\n",
        "metadata = {\n",
        "    'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "\n",
        "    'total_records': int(df_encoded.shape[0]),\n",
        "    'total_columns': int(df_encoded.shape[1]),\n",
        "\n",
        "    'seasons_covered': (\n",
        "        sorted(df_encoded['season'].unique().tolist())\n",
        "        if 'season' in df_encoded.columns else []\n",
        "    ),\n",
        "\n",
        "    'unique_players': (\n",
        "        int(df_encoded['player_name'].nunique())\n",
        "        if 'player_name' in df_encoded.columns else None\n",
        "    ),\n",
        "\n",
        "    'key_features': {\n",
        "        'identity': [c for c in ['player_name','first_name','second_name'] if c in df_encoded.columns],\n",
        "        'categorical': [c for c in ['season'] if c in df_encoded.columns],\n",
        "        'encoded': [c for c in df_encoded.columns if c.endswith('_encoded')],\n",
        "        'performance': [c for c in ['total_points','minutes'] if c in df_encoded.columns],\n",
        "        'offensive': [c for c in ['goals_scored','assists','goal_involvement'] if c in df_encoded.columns],\n",
        "        'defensive': [c for c in ['clean_sheets','goals_conceded'] if c in df_encoded.columns],\n",
        "        'derived': [\n",
        "            c for c in [\n",
        "                'goals_per_90','assists_per_90','clean_sheet_rate',\n",
        "                'rank_in_season','points_per_cost'\n",
        "            ] if c in df_encoded.columns\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    'filtering_criteria': {\n",
        "        'min_minutes': int(min_minutes),\n",
        "        'players_filtered_out': int(filtered_out)\n",
        "    }\n",
        "}\n",
        "\n",
        "output_metadata = processed_path / 'metadata.json'\n",
        "with open(output_metadata, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Metadata saved:\")\n",
        "print(f\"   üìÅ {output_metadata}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
